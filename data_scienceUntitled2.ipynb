{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yogesh-commoner/pandas-handling-missing-values/blob/main/data_scienceUntitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uda-fxyeZwCE",
        "outputId": "57a8dc3f-64b2-4d59-d144-1e2f4cd16aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exercise 1:\n",
            "                  values\n",
            "letters numbers        \n",
            "A       1            10\n",
            "        2            20\n",
            "B       1            30\n",
            "        2            40\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Exercise 1: Create a MultiIndex from a DataFrame\n",
        "arrays = [['A', 'A', 'B', 'B'], [1, 2, 1, 2]]\n",
        "index = pd.MultiIndex.from_arrays(arrays, names=('letters', 'numbers'))\n",
        "df = pd.DataFrame({'values': [10, 20, 30, 40]}, index=index)\n",
        "print(\"Exercise 1:\\n\", df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1: Create a MultiIndex from a DataFrame\n",
        "from_arrays() is used to create a MultiIndex with two levels: letters and numbers.\n",
        "The DataFrame is indexed using this MultiIndex."
      ],
      "metadata": {
        "id": "cVHEvWkwayue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2: Create a MultiIndex using from_tuples()\n",
        "arrays = [('A', 1), ('A', 2), ('B', 1), ('B', 2)]\n",
        "index = pd.MultiIndex.from_tuples(arrays, names=('letters', 'numbers'))\n",
        "df = pd.DataFrame({'values': [10, 20, 30, 40]}, index=index)\n",
        "print(\"\\nExercise 2:\\n\", df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVnQpEzNa05s",
        "outputId": "da82aab7-f13f-4c3f-fab0-1700048dbd3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exercise 2:\n",
            "                  values\n",
            "letters numbers        \n",
            "A       1            10\n",
            "        2            20\n",
            "B       1            30\n",
            "        2            40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2: Create a MultiIndex using from_tuples()\n",
        "Instead of arrays, we use tuples to define the MultiIndex structure.\n",
        "The result is similar to Exercise 1"
      ],
      "metadata": {
        "id": "poBkZw2sa3nT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 3: Create a MultiIndex using from_product()\n",
        "index = pd.MultiIndex.from_product([['A', 'B'], [1, 2]], names=('letters', 'numbers'))\n",
        "df = pd.DataFrame({'values': [10, 20, 30, 40]}, index=index)\n",
        "print(\"\\nExercise 3:\\n\", df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5EcycbFa8Ms",
        "outputId": "7f5e52e2-8f1a-4a55-b4be-95b19a92c4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exercise 3:\n",
            "                  values\n",
            "letters numbers        \n",
            "A       1            10\n",
            "        2            20\n",
            "B       1            30\n",
            "        2            40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 3: Create a MultiIndex using from_product()\n",
        "Generates all possible combinations of two lists using from_product().\n",
        "This ensures structured hierarchical indexing."
      ],
      "metadata": {
        "id": "2CwP7LanbEu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 4: Create a MultiIndex using set_index()\n",
        "df = pd.DataFrame({'letters': ['A', 'A', 'B', 'B'], 'numbers': [1, 2, 1, 2], 'values': [10, 20, 30, 40]})\n",
        "df = df.set_index(['letters', 'numbers'])\n",
        "print(\"\\nExercise 4:\\n\", df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQPTxS2MbGyE",
        "outputId": "9bf747f8-af78-42de-9145-1ce326e22375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exercise 4:\n",
            "                  values\n",
            "letters numbers        \n",
            "A       1            10\n",
            "        2            20\n",
            "B       1            30\n",
            "        2            40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 5: Remove index levels from a MultiIndex\n",
        "reset_index() removes the MultiIndex and turns them back into columns."
      ],
      "metadata": {
        "id": "FHujeDPzbIz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 6: Sort a MultiIndex DataFrame\n",
        "df = df.set_index(['letters', 'numbers']).sort_index()\n",
        "print(\"\\nExercise 6:\\n\", df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "collapsed": true,
        "id": "Flq2nV8KbK2c",
        "outputId": "328116c6-98ad-49b0-a1f2-ea79e268a454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of ['letters', 'numbers'] are in the columns\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-da853cd3db42>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Exercise 6: Sort a MultiIndex DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'letters'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'numbers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nExercise 6:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   6120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of ['letters', 'numbers'] are in the columns\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 6: Sort a MultiIndex DataFrame\n",
        "sort_index() sorts the MultiIndex in ascending order."
      ],
      "metadata": {
        "id": "jl4VeNXebPhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Exercise 7: Swap levels in a MultiIndex DataFrame\n",
        "df = df.swaplevel()\n",
        "print(\"\\nExercise 7:\\n\", df)"
      ],
      "metadata": {
        "id": "X68TS71LbWHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 7: Swap levels in a MultiIndex DataFrame\n",
        "swaplevel() swaps the two index levels."
      ],
      "metadata": {
        "id": "-BtM05Zybcm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Exercise 7: Swap levels in a MultiIndex DataFrame\n",
        "df = df.swaplevel()\n",
        "print(\"\\nExercise 7:\\n\", df)"
      ],
      "metadata": {
        "id": "D31OCJlWbe1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 7: Swap levels in a MultiIndex DataFrame\n",
        "swaplevel() swaps the two index levels."
      ],
      "metadata": {
        "id": "VeLYCVT_bvhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 8: Select a specific subset from a MultiIndex DataFrame\n",
        "print(\"\\nExercise 8:\\n\", df.loc['A'])"
      ],
      "metadata": {
        "id": "-0mrf9vbbxEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 8: Select a specific subset from a MultiIndex DataFrame\n",
        ".loc[] is used to select all rows where the first index level is 'A'."
      ],
      "metadata": {
        "id": "JFHlbIuVbzwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 9: Perform a cross-section (xs) on a MultiIndex DataFrame\n",
        "print(\"\\nExercise 9:\\n\", df.xs(1, level='numbers'))\n"
      ],
      "metadata": {
        "id": "F8VE4LMRcKxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 9: Perform a cross-section (xs()) on a MultiIndex DataFrame\n",
        "xs() extracts all rows where the numbers index level is 1."
      ],
      "metadata": {
        "id": "RISKzVLOcMps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 10: Apply a function to a level in a MultiIndex DataFrame\n",
        "df['values'] = df['values'].groupby(level='letters').transform(lambda x: x * 2)\n",
        "print(\"\\nExercise 10:\\n\", df)"
      ],
      "metadata": {
        "id": "4sjuUe0TcOj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 10: Apply a function to a level in a MultiIndex DataFrame\n",
        "Groups the values column by letters and multiplies them by 2."
      ],
      "metadata": {
        "id": "NQaqszbOcQT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 11: Rename MultiIndex levels\n",
        "df = df.rename_axis(index={'letters': 'alpha', 'numbers': 'num'})\n",
        "print(\"\\nExercise 11:\\n\", df)"
      ],
      "metadata": {
        "id": "983ijR_kcRuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 11: Rename MultiIndex levels\n",
        "rename_axis() renames the index levels from letters → alpha and numbers → num."
      ],
      "metadata": {
        "id": "_vjeIvtwcUdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 12: Remove a level from MultiIndex using droplevel()\n",
        "df = df.droplevel('num')\n",
        "print(\"\\nExercise 12:\\n\", df)"
      ],
      "metadata": {
        "id": "7t9RHy-6cXWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 12: Remove a level from MultiIndex using droplevel()\n",
        "droplevel('num') removes the numbers index level."
      ],
      "metadata": {
        "id": "AIlYN-7vcfQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 13: Check for uniqueness in MultiIndex DataFrame\n",
        "print(\"\\nExercise 13:\\n\", df.index.is_unique)"
      ],
      "metadata": {
        "id": "YFToSoLTciaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 13: Check for uniqueness in MultiIndex DataFrame\n",
        "df.index.is_unique checks if each index combination is unique."
      ],
      "metadata": {
        "id": "ltS6-3zCclHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 14: Convert a MultiIndex DataFrame to a flat DataFrame\n",
        "df = df.reset_index()\n",
        "print(\"\\nExercise 14:\\n\", df)"
      ],
      "metadata": {
        "id": "V_agtRKtcoh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 14: Convert a MultiIndex DataFrame to a flat DataFrame\n",
        "reset_index() is used again to flatten the MultiIndex into regular columns."
      ],
      "metadata": {
        "id": "mkvp4KIocqoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Exercise 15: Create a Pivot Table from a MultiIndex DataFrame\n",
        "df = pd.DataFrame({'letters': ['A', 'A', 'B', 'B'], 'numbers': [1, 2, 1, 2], 'values': [10, 20, 30, 40]})\n",
        "pivot_table = df.pivot_table(values='values', index='letters', columns='numbers', aggfunc='sum')\n",
        "print(\"\\nExercise 15:\\n\", pivot_table)"
      ],
      "metadata": {
        "id": "I9AzpdJ6ctzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 15: Create a Pivot Table from a MultiIndex DataFrame\n",
        "pivot_table() restructures the DataFrame, organizing values by letters and numbers.\n"
      ],
      "metadata": {
        "id": "mzc79hQFcwnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas Filter [ 27 exercises with solution ]"
      ],
      "metadata": {
        "id": "Rdjo3uqtcy8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nSplit the said data on school_code wise:')\n",
        "result = student_data.groupby(['school_code'])\n",
        "for name,group in result:\n",
        "    print(\"\\nGroup:\")\n",
        "    print(name)\n",
        "    print(group)\n",
        "print(\"\\nType of the object:\")\n",
        "print(type(result))\n"
      ],
      "metadata": {
        "id": "IHcD-jkqc3G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Groups the DataFrame by column 'A' and counts the number of rows in each group.\n",
        "This is useful for understanding how frequently each category appears in the dataset. It helps summarize categorical data efficiently."
      ],
      "metadata": {
        "id": "52_Y7Qm1fhsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nSplit the said data on school_code wise:')\n",
        "result = student_data.groupby(['school_code'])\n",
        "for name,group in result:\n",
        "    print(\"\\nGroup:\")\n",
        "    print(name)\n",
        "    print(group)\n",
        "print(\"\\nType of the object:\")\n",
        "print(type(result))\n"
      ],
      "metadata": {
        "id": "uJkyfqX-fi79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Groups the DataFrame by multiple columns ('A' and 'B') and counts the number of occurrences for each combination.\n",
        "This allows analyzing relationships between multiple categorical variables and identifying common patterns."
      ],
      "metadata": {
        "id": "aT6LPVXjfnat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nSplit the said data on school_code, class wise:')\n",
        "result = student_data.groupby(['school_code', 'class'])\n",
        "for name,group in result:\n",
        "    print(\"\\nGroup:\")\n",
        "    print(name)\n",
        "    print(group)\n"
      ],
      "metadata": {
        "id": "HDBPVIpkfol1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Groups the DataFrame by column 'A' and calculates the sum of numeric columns for each group.\n",
        "This is useful when aggregating transaction amounts, total sales, or any other measurable quantities.\n",
        "\n"
      ],
      "metadata": {
        "id": "jCKoOw35f16a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nCast grouping as a list:')\n",
        "result = student_data.groupby(['school_code'])\n",
        "print(list(result))\n"
      ],
      "metadata": {
        "id": "RJdtXWTJf4bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Groups the DataFrame by column 'A' and calculates the sum of numeric columns for each group.\n",
        "This is useful when aggregating transaction amounts, total sales, or any other measurable quantities.\n",
        "\n"
      ],
      "metadata": {
        "id": "2OQxJjpZgDc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nCast grouping as a list:')\n",
        "result = student_data.groupby(['school_code'])\n",
        "print(list(result))\n"
      ],
      "metadata": {
        "id": "nL0kWxk7gHb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finds the mean of numeric columns for each unique group in column 'A'.\n",
        "This helps in understanding the average values per category, useful in analyzing trends like average sales or performance per group."
      ],
      "metadata": {
        "id": "T2ye7y_tgL4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nSplit the said data on school_code wise:')\n",
        "grouped_single = student_data.groupby(['school_code'])\n",
        "print(\"Size of the grouped data - single column\")\n",
        "print(grouped_single.size())\n",
        "print('\\nSplit the said data on school_code and class wise:')\n",
        "\n",
        "grouped_mul = student_data.groupby(['school_code', 'class'])\n",
        "print(\"Size of the grouped data - multiple columns:\")\n",
        "print(grouped_mul.size())\n"
      ],
      "metadata": {
        "id": "G-ZglmrJgOy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applies multiple aggregation functions (like sum, mean) to grouped data at once.\n",
        "This allows retrieving multiple summary statistics efficiently without requiring multiple groupby operations."
      ],
      "metadata": {
        "id": "MfqmUiBngUom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nSplit the said data on school_code wise:')\n",
        "grouped = student_data.groupby(['school_code'])\n",
        "print(\"Call school code 's001':\")\n",
        "print(grouped.get_group('s001'))\n",
        "print(\"\\nCall school code 's004':\")\n",
        "print(grouped.get_group('s004'))\n"
      ],
      "metadata": {
        "id": "3jQrTt2IgVKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filters out groups where the sum of column 'C' is less than or equal to 3.\n",
        "This helps in keeping only significant groups that meet a certain threshold, useful in financial and business analytics."
      ],
      "metadata": {
        "id": "Zgd93qeYgbIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "orders_data = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3005,3001,3002,3009,3005,3007,3002,3004,3009,3008,3003,3002],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(orders_data)\n",
        "result = orders_data.groupby('customer_id').agg({'purch_amt': ['mean', 'min', 'max']})\n",
        "print(\"\\nMean, min, and max values of purchase amount (purch_amt) group by customer id  (customer_id).\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "5n3AZjlagdcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterates over grouped DataFrame, printing each group separately.\n",
        "This helps inspect each category and its corresponding data, which is useful for debugging or exploratory analysis."
      ],
      "metadata": {
        "id": "KHflx8HKgg7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "orders_data = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3005,3001,3002,3009,3005,3007,3002,3004,3009,3008,3003,3002],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(orders_data)\n",
        "print(\"\\nGroup by two columns and count by each row:\")\n",
        "result = orders_data.groupby(['salesman_id','customer_id']).size().reset_index().groupby(['salesman_id','customer_id'])[[0]].max()\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "LZxnnicJgiuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforms column 'C' by subtracting the mean of 'C' within each group.\n",
        "This normalization method helps in making data comparable within groups, which is useful for statistical modeling."
      ],
      "metadata": {
        "id": "MQG_3OvsgmIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "df_agg = df.groupby(['customer_id','salesman_id']).agg({'purch_amt':sum})\n",
        "result = df_agg['purch_amt'].groupby(level=0, group_keys=False)\n",
        "print(\"\\nGroup on 'customer_id', 'salesman_id' and then sort sum of purch_amt within the groups:\")\n",
        "print(result.nlargest())\n"
      ],
      "metadata": {
        "id": "7ndmoPkKgojX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computes the percentage of each value in column 'C' relative to the group’s total.\n",
        "This is useful for analyzing the proportion of a category’s contribution within a group, such as percentage sales per region."
      ],
      "metadata": {
        "id": "zJ0mIOL2grRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "result = df.groupby('customer_id')['ord_date'].apply(list)\n",
        "print(\"\\nGroup on 'customer_id' and display the list of order dates in group wise:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "-iD_QCWXgtHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finds the largest n values in column 'C' for each group.\n",
        "This is helpful for ranking items within categories, such as identifying the top-selling products in each region."
      ],
      "metadata": {
        "id": "BFeDmHrUgwIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['05-10-2012','09-10-2012','05-10-2012','08-17-2012','10-09-2012','07-27-2012','10-09-2012','10-10-2012','10-10-2012','06-17-2012','07-08-2012','04-25-2012'],\n",
        "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "df['ord_date']= pd.to_datetime(df['ord_date'])\n",
        "print(\"\\nMonth wise purchase amount:\")\n",
        "result = df.set_index('ord_date').groupby(pd.Grouper(freq='M')).agg({'purch_amt':sum})\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "VC7O5WZGg0K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates a pivot table summarizing column 'C' values grouped by column 'A'.\n",
        "Pivot tables make it easier to visualize aggregated data and analyze trends across different groups."
      ],
      "metadata": {
        "id": "UNFvFlH2g2rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['05-10-2012','09-10-2012','05-10-2013','08-17-2013','10-09-2013','07-27-2014','10-09-2012','10-10-2012','10-10-2012','06-17-2014','07-08-2012','04-25-2012'],\n",
        "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "df['ord_date']= pd.to_datetime(df['ord_date'])\n",
        "print(\"\\nYear wise Month wise purchase amount:\")\n",
        "result = df.groupby([df['ord_date'].dt.year, df['ord_date'].dt.month]).agg({'purch_amt':sum})\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "xRhxTDDDhC5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computes the cumulative sum of column 'C' within each group.\n",
        "This is used to track running totals, such as cumulative sales or stock levels over time."
      ],
      "metadata": {
        "id": "pT8tWcMVhFoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame( {'X' : [10, 10, 10, 20, 30, 30, 10],\n",
        "                    'Y' : [10, 15, 11, 20, 21, 12, 14],\n",
        "                    'Z' : [22, 20, 18, 20, 13, 10, 0]})\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "result= df.groupby('X').aggregate(lambda tdf: tdf.unique().tolist())\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "_s73ldhQhHku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fills missing values in column 'C' using the mean of 'C' for each group.\n",
        "This method ensures missing data does not skew analysis, especially useful in machine learning preprocessing."
      ],
      "metadata": {
        "id": "kh_JMlaQhLXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame( {'id' : [1, 2, 1, 1, 2, 1, 2],\n",
        "                    'type' : [10, 15, 11, 20, 21, 12, 14],\n",
        "                    'book' : ['Math','English','Physics','Math','English','Physics','English']})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "result = df.groupby(['id', 'type', 'book']).size().unstack(fill_value=0)\n",
        "print(\"\\nResult:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "W7t4bOC3hM82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ranks values in column 'C' within each group.\n",
        "This assigns a ranking to each value, useful in competitions, sales leaderboards, and percentile calculations."
      ],
      "metadata": {
        "id": "xpYv8HLThSDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame( {'id' : [1, 2, 1, 1, 2, 1, 2],\n",
        "                    'type' : [10, 15, 11, 20, 21, 12, 14],\n",
        "                    'book' : ['Math','English','Physics','Math','English','Physics','English']})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "result = df.groupby(['id', 'type', 'book']).size().unstack(fill_value=0)\n",
        "print(\"\\nResult:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "SqoA6mF0hUDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieves the first row from each group.\n",
        "This is useful when extracting initial transactions, earliest dates, or first occurrences of events per category."
      ],
      "metadata": {
        "id": "43j9BHpphej2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "df = pd.DataFrame({\n",
        "'book_name':['Book1','Book2','Book3','Book4','Book1','Book2','Book3','Book5'],\n",
        "'book_type':['Math','Physics','Computer','Science','Math','Physics','Computer','English'],\n",
        "'book_id':[1,2,3,4,1,2,3,5]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nNew column with count from groupby:\")\n",
        "result = df.groupby([\"book_name\", \"book_type\"])[\"book_type\"].count().reset_index(name=\"count\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "OxRTsEt5hgye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counts the number of unique values in column 'C' within each group.\n",
        "This helps analyze the diversity of values in each category, such as unique products sold per store."
      ],
      "metadata": {
        "id": "VMrfEjeThkJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'customer_id':[3005,3001,3002,3009,3005,3007,3002,3004,3009,3008,3003,3002],\n",
        "'sales_id':[5002,5003,5004,5003,5002,5001,5005,5007,5008,5004,5005,5001]})\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "groups = df.groupby(['customer_id', pd.cut(df.sales_id, 3)])\n",
        "result = groups.size().unstack()\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "bNMMfJKThoiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filters out groups that have only one row, keeping only those with multiple records.\n",
        "This is useful for analyzing repeated events and ignoring single-instance occurrences."
      ],
      "metadata": {
        "id": "KA_TP-vZhr7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s001'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nGroup by with multiple aggregations:\")\n",
        "result = df.groupby(['school_code','class']).agg({'height': ['max', 'mean'],\n",
        "                                 'weight': ['sum','min','count']})\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "CFWnBse4ht3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finds the minimum and maximum value of column 'C' in each group.\n",
        "This helps determine the range of values within a category, such as lowest and highest prices per brand."
      ],
      "metadata": {
        "id": "seJgq28_hw1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame( {'id' : ['A','A','A','A','A','A','B','B','B','B','B'],\n",
        "                    'type' : [1,1,1,1,2,2,1,1,1,2,2],\n",
        "                    'book' : ['Math','Math','English','Physics','Math','English','Physics','English','Physics','English','English']})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "new_df = df[['id', 'type', 'book']].drop_duplicates()\\\n",
        "                         .groupby(['id','type'])['book']\\\n",
        "                         .apply(list)\\\n",
        "                         .reset_index()\n",
        "\n",
        "new_df['book'] = new_df.apply(lambda x: (','.join([str(s) for s in x['book']])), axis = 1)\n",
        "print(\"\\nList all unique values in a group:\")\n",
        "print(new_df)\n"
      ],
      "metadata": {
        "id": "GmFnu5pLhyse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counts the number of missing values in each group.\n",
        "This helps in data cleaning by identifying categories with high levels of missing data."
      ],
      "metadata": {
        "id": "r_KZfcICh2MF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    ' height ': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nMean, min, and max value of age for each school with customized column names:')\n",
        "grouped_single = student_data.groupby('school_code').agg(Age_Mean = ('age','mean'),Age_Max=('age',max),Age_Min=('age',min))\n",
        "print(grouped_single)\n"
      ],
      "metadata": {
        "id": "pabOMCZlh5s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computes the median of column 'C' within each group.\n",
        "The median is useful when analyzing skewed data, such as income distributions within different demographics."
      ],
      "metadata": {
        "id": "ZvL4XPzDh_zA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'ord_date': ['05-10-2012','09-10-2012','05-10-2012','08-17-2012','10-09-2012','07-27-2012','10-09-2012','10-10-2012','10-10-2012','06-17-2012','07-08-2012','04-25-2012'],\n",
        "'customer_id':['C3001','C3001','D3005','D3001','C3005','D3001','C3005','D3001','D3005','C3001','D3005','D3005'],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "def customer_id_C(x):\n",
        "    return (x.str[0] == 'C').sum()\n",
        "result = df.groupby(['salesman_id'])\\\n",
        "  .agg(customer_id_start_C = ('customer_id', customer_id_C),\n",
        "       customer_id_list = ('customer_id', lambda x: ', '.join(x)),\n",
        "       purchase_amt_gap   = ('purch_amt', lambda x: x.max()-x.min())\n",
        "      )\n",
        "print(\"\\nNumber of customers  starting with ‘C’, the list of all products and the difference of maximum purchase amount and minimum purchase amount:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "ySzShkiQiEHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finds the variance of column 'C' within each group.\n",
        "Variance measures data dispersion, helping understand consistency within groups, such as customer spending habits."
      ],
      "metadata": {
        "id": "n_OWqxcYiH7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['05-10-2012','09-10-2012','05-10-2012','08-17-2012','10-09-2012','07-27-2012','10-09-2012','10-10-2012','10-10-2012','06-17-2012','07-08-2012','04-25-2012'],\n",
        "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "gr_data = df.groupby(['customer_id','salesman_id']).agg({'purch_amt': 'sum'})\n",
        "gr_data[\"% (Purch Amt.)\"] = gr_data.apply(lambda x:  100*x / x.sum())\n",
        "print(\"\\nPercentage of purch_amt in each group of customer_id:\")\n",
        "print(gr_data)\n"
      ],
      "metadata": {
        "id": "SwMCk3HaiKU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computes the standard deviation of column 'C' within each group.\n",
        "Standard deviation is useful for analyzing volatility, such as stock price fluctuations within different sectors."
      ],
      "metadata": {
        "id": "lookgJMoiOu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "dict_data_list = list()\n",
        "\n",
        "for gg, dd in df.groupby(['school_code','class']):\n",
        "    group = dict(zip(['school_code','class'], gg))\n",
        "    ocolumns_list = list()\n",
        "    for _, data in dd.iterrows():\n",
        "        data = data.drop(labels=['school_code','class'])\n",
        "        ocolumns_list.append(data.to_dict())\n",
        "    group['other_columns'] = ocolumns_list\n",
        "    dict_data_list.append(group)\n",
        "\n",
        "print(dict_data_list)\n"
      ],
      "metadata": {
        "id": "eqT9GjpFiSW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates a new column storing the mean of 'C' for each group.\n",
        "This is useful for comparing each value to its group’s average, helping in anomaly detection."
      ],
      "metadata": {
        "id": "L1t9hLXgiXtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001],\n",
        "'sale_jan':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 1760, 2983.43, 480.4,  1250.45, 75.29,1045.6],\n",
        "'sale_feb':[250.5, 170.65, 15.26, 110.5, 598.5, 1400.6, 2760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_mar':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_apr':[150.5, 270.65, 95.26, 210.5, 948.5, 2400.6, 760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_may':[130.5, 270.65, 65.26, 310.5, 948.5, 2400.6, 760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_jun':[150.5, 270.65, 45.26, 110.5, 948.5, 3400.6, 5760, 983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_jul':[950.5, 270.65, 65.26, 210.5, 948.5, 2400.6, 5760, 983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_aug':[150.5, 70.65,  65.26, 110.5, 948.5, 400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_sep':[150.5, 270.65, 65.26, 110.5, 948.5, 200.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_oct':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_nov':[150.5, 270.65, 95.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_dec':[150.5, 70.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6]\n",
        "})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\Result after group on salesman_id and apply different aggregate functions:\")\n",
        "df = df.groupby('salesman_id').agg(lambda x : x.sum() if x.name in ['sale_jan','sale_feb','sale_mar'] else x.mean())\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "LckZU3u3iZH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computes a rolling mean of column 'C' within each group.\n",
        "Rolling means smooth out fluctuations over a moving window, useful in trend analysis like sales forecasts"
      ],
      "metadata": {
        "id": "1LAkI27hijlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'salesman_id': [5001,5002,5003,5004,5005,5006,5007,5008,5009,5010,5011,5012],\n",
        "'sale_jan':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 1760, 2983.43, 480.4,  1250.45, 75.29,1045.6]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "result = df.groupby(pd.cut(df['salesman_id'],\n",
        "                  bins=[0,5006,np.inf],\n",
        "                  labels=['S1', 'S2']))['sale_jan'].sum().reset_index()\n",
        "print(\"\\nGroupBy with condition of  two labels and ranges:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "x7aJZtTPikBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computes an expanding sum of column 'C' within each group.\n",
        "Expanding sums show cumulative growth, such as total revenue over time for different regions."
      ],
      "metadata": {
        "id": "UlcggIJmin2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "    'student_id': ['S001','S001','S002','S002','S003','S003'],\n",
        "    'marks': [[88,89,90],[78,81,60],[84,83,91],[84,88,91],[90,89,92],[88,59,90]]})\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nGroupby and aggregate over multiple lists:\")\n",
        "result = df.set_index('student_id')['marks'].groupby('student_id').apply(list).apply(lambda x: np.mean(x,0))\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "mgpC2Y3wisvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finds the correlation between columns 'B' and 'C' within each group.\n",
        "Correlation analysis helps understand relationships, such as whether increased marketing ('B') affects sales ('C').\n",
        "\n"
      ],
      "metadata": {
        "id": "8BIihFD6i80K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3005,3001,3002,3009,3005,3007,3002,3004,3009,3008,3003,3002],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5004,5003,5002,5004,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nGroupby to find first order date for each group(salesman_id):\")\n",
        "result = df.groupby('salesman_id')['ord_date'].min()\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "XNzhburpi_Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computes the cumulative product of column 'C' within each group.\n",
        "This is useful for scenarios involving continuous growth rates, such as compound interest or population growth.\n",
        "\n"
      ],
      "metadata": {
        "id": "uknQUmtejDbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3002,3001,3001,3003,3002,3002,3001,3004,3003,3002,3003,3001],\n",
        "'salesman_id':[5002,5003,5001,5003,5002,5001,5001,5003,5003,5002,5003,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nSplit the said data on 'salesman_id', 'customer_id' wise:\")\n",
        "result = df.groupby(['salesman_id', 'customer_id'])\n",
        "for name,group in result:\n",
        "    print(\"\\nGroup:\")\n",
        "    print(name)\n",
        "    print(group)\n",
        "n = 2\n",
        "#result1 = df.groupby(['salesman_id', 'customer_id']).tail(n).index, axis=0)\n",
        "print(\"\\nDroping last two records:\")\n",
        "result1 = df.drop(df.groupby(['salesman_id', 'customer_id']).tail(n).index, axis=0)\n",
        "print(result1)\n"
      ],
      "metadata": {
        "id": "r39BrUkZjF8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finds the most frequent (mode) value of column 'C' within each group.\n",
        "The mode identifies the most common occurrence, such as the most popular product purchased per store."
      ],
      "metadata": {
        "id": "Jh2zPq11jKBG"
      }
    }
  ]
}